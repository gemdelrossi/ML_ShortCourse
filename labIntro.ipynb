{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/agpo-ilr-uni-bonn/PromotionskollegModule6800_2024/blob/master/labIntro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k10_r9GL8YlT"
   },
   "source": [
    "### Intro notebook for the course: \"Machine Learning in applied economic analysis\"\n",
    "### Promotionskolleg Module 6800, September 2-6, 2024\n",
    "\n",
    "#### Instructors\n",
    "- Kathy Baylis\n",
    "- Thomas Heckelei\n",
    "- Hugo Storm\n",
    "\n",
    "#### Description\n",
    "This notebook is intended to get you familiar with some of the most common data science / ML libaries typically used in python.\n",
    "In this notebook you will 1) load data, 2) prepare the data for running your models, 3) run a simple logistic regression, 4) run a very simiple neural network, and 5) compare the results of the two models. You will learn in the course that a logistic regression is actually a special case of a very simple neural network! So if you have run a logistic regression you have actually worked with NN...\n",
    "\n",
    "Work Steps\n",
    "\n",
    "1. (If you are reading this in Github and haven't yet opened it in colab,) Open this notebook in google colab (https://colab.research.google.com/) using the link provided above. To run the notebook you need to have a google account.\n",
    "\n",
    "2. Execute all code cells below (Runtime/Run all) and try to understand what is going on.\n",
    "\n",
    "3. Two important python libraries for working with data in python are numpy and pandas. There are plenty of tutorials online to get you a first idea of how they work. Two examples are provided here. For taking the course you do not have to be an expert in using those libraries but having a first basic understanding of the functionality will certainly help you to follow the examples.\n",
    "    \n",
    "- Numpy: https://www.datacamp.com/community/tutorials/python-numpy-tutorial\n",
    "\n",
    "- Pandas: https://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html#min   \n",
    "\n",
    "4. (Optional) Play around with the notebook and make some changes (no worries you can not break it...). Here are some ideas what you can try to achieve:\n",
    "\n",
    "- In the data set there are many more variables. Figure out how they are named and add a couple more variables to two models. Run the models and see how this changes the quality of the model prediction (in terms of R²).\n",
    "\n",
    "-  If you want to go a step further... Create some new variables by adding interaction terms or square/cube terms. See if this increases model performance (R²).\n",
    "\n",
    "- Are you up for the challenge (before even starting with the course)? The sklearn libary implements a large number of ML models. We will cover the most important ones in this course. In this notebook you have already seen how to use the logistic regression or a neural network in sklearn. Try to adjust the code to run an additional model, for example a random forest (will be covered on day 2 in the course). There are plenty of tutorials online (for example https://www.datacamp.com/community/tutorials/random-forests-classifier-python). Hint: there is basically only one line of code that you need to change in order to run an random forest with sklearn instead of a logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m9uNLCh58YlU"
   },
   "source": [
    "#### Load relevant libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "w_wnzeZx8YlV"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import scipy.stats as stat\n",
    "from scipy.stats import norm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01gwbHWy8Ylc"
   },
   "source": [
    "#### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5rQhcbrS8Ylh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in c:\\users\\gemma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# run this cell only once if you don't have wget installed\n",
    "# its assumed you are using windows and have python installed\n",
    "# only needed if you are running the notebook locally\n",
    "%pip install wget\n",
    "if not os.path.isfile('brazil_all_data_v2.gz'):\n",
    "    !python -m wget  https://ilr-ml.s3.eu-central-1.amazonaws.com/brazil_all_data_v2.gz\n",
    "# Download data only once and make sure it is in the same folder as the notebook\n",
    "\n",
    "# check if brazil_all_data_v2.gz is available in the current folder and if not, download it\n",
    "\n",
    "if not os.path.isfile('brazil_all_data_v2.gz'):\n",
    "    !wget  https://ilr-ml.s3.eu-central-1.amazonaws.com/brazil_all_data_v2.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "gfWHYVAT8Ylk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  row  col        lon        lat       bean     carrot  cassava  \\\n",
      "0   0    0    0 -59.989876 -10.010125  200.00000  335.00000    201.0   \n",
      "1   1    0    1 -59.969875 -10.010125  200.00000  335.00000    201.0   \n",
      "2   2    0    2 -59.949875 -10.010125  200.00000  335.00000    201.0   \n",
      "3   3    0    3 -59.929874 -10.010125  200.00000  335.00000    201.0   \n",
      "4   4    0    4 -59.909874 -10.010125  218.33334  435.83334    216.0   \n",
      "\n",
      "   chickpea  citrus  ...  tot_defor_2010_lag_3rd_order  \\\n",
      "0       0.0   391.0  ...                      1.800000   \n",
      "1       0.0   391.0  ...                      1.052631   \n",
      "2       0.0   391.0  ...                      3.652174   \n",
      "3       0.0   391.0  ...                      3.814815   \n",
      "4       0.0   523.5  ...                      8.296296   \n",
      "\n",
      "   tot_defor_2011_lag_3rd_order  tot_defor_2012_lag_3rd_order  \\\n",
      "0                      1.333333                      6.866667   \n",
      "1                      2.000000                      5.105263   \n",
      "2                      1.652174                      5.913043   \n",
      "3                      2.666667                      5.407407   \n",
      "4                      2.629630                      5.222222   \n",
      "\n",
      "   tot_defor_2013_lag_3rd_order  tot_defor_2014_lag_3rd_order  \\\n",
      "0                      0.733333                      2.200000   \n",
      "1                      0.526316                      0.947368   \n",
      "2                      4.086957                      4.521739   \n",
      "3                      4.000000                      3.925926   \n",
      "4                      7.592592                      5.370370   \n",
      "\n",
      "   tot_defor_2015_lag_3rd_order  tot_defor_2016_lag_3rd_order  \\\n",
      "0                      4.466667                      9.866667   \n",
      "1                      1.473684                      9.473684   \n",
      "2                      4.956522                      8.695652   \n",
      "3                      3.703704                      5.888889   \n",
      "4                      4.481482                      8.888889   \n",
      "\n",
      "   tot_defor_2017_lag_3rd_order  tot_defor_2018_lag_3rd_order  s  \n",
      "0                      6.600000                      0.800000  1  \n",
      "1                      6.210527                      2.000000  1  \n",
      "2                     11.217392                      5.173913  1  \n",
      "3                     19.629629                      6.518518  1  \n",
      "4                     18.888889                      5.222222  1  \n",
      "\n",
      "[5 rows x 426 columns]\n",
      "(249940, 426)\n"
     ]
    }
   ],
   "source": [
    "# Load data with pandas into a dataframe\n",
    "df = pd.read_parquet('brazil_all_data_v2.gz')\n",
    "\n",
    "df.head()\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1WUBlF368Ylr"
   },
   "source": [
    "#### Setup dependent and explantory variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ivZFEoz28Yls"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1     True\n",
      "2    False\n",
      "3    False\n",
      "4     True\n",
      "5     True\n",
      "6     True\n",
      "7    False\n",
      "8     True\n",
      "9     True\n",
      "Name: D_defor_2018, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# Define binary variable for deforestration called D_defor_2018 from defor_2018\n",
    "df['D_defor_2018'] = df['defor_2018']>0 # true false\n",
    "\n",
    "print(df['D_defor_2018'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "dWl0aefa8Ylx"
   },
   "outputs": [],
   "source": [
    "# Add a variable, called constant, with only ones to the dataframe\n",
    "df['constant'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "x8gzlvci8Yl1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>row</th>\n",
       "      <th>col</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>bean</th>\n",
       "      <th>carrot</th>\n",
       "      <th>cassava</th>\n",
       "      <th>chickpea</th>\n",
       "      <th>citrus</th>\n",
       "      <th>...</th>\n",
       "      <th>tot_defor_2012_lag_3rd_order</th>\n",
       "      <th>tot_defor_2013_lag_3rd_order</th>\n",
       "      <th>tot_defor_2014_lag_3rd_order</th>\n",
       "      <th>tot_defor_2015_lag_3rd_order</th>\n",
       "      <th>tot_defor_2016_lag_3rd_order</th>\n",
       "      <th>tot_defor_2017_lag_3rd_order</th>\n",
       "      <th>tot_defor_2018_lag_3rd_order</th>\n",
       "      <th>s</th>\n",
       "      <th>D_defor_2018</th>\n",
       "      <th>constant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-59.989876</td>\n",
       "      <td>-10.010125</td>\n",
       "      <td>200.00000</td>\n",
       "      <td>335.00000</td>\n",
       "      <td>201.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.866667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>4.466667</td>\n",
       "      <td>9.866667</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-59.969875</td>\n",
       "      <td>-10.010125</td>\n",
       "      <td>200.00000</td>\n",
       "      <td>335.00000</td>\n",
       "      <td>201.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.105263</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>1.473684</td>\n",
       "      <td>9.473684</td>\n",
       "      <td>6.210527</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-59.949875</td>\n",
       "      <td>-10.010125</td>\n",
       "      <td>200.00000</td>\n",
       "      <td>335.00000</td>\n",
       "      <td>201.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.913043</td>\n",
       "      <td>4.086957</td>\n",
       "      <td>4.521739</td>\n",
       "      <td>4.956522</td>\n",
       "      <td>8.695652</td>\n",
       "      <td>11.217392</td>\n",
       "      <td>5.173913</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-59.929874</td>\n",
       "      <td>-10.010125</td>\n",
       "      <td>200.00000</td>\n",
       "      <td>335.00000</td>\n",
       "      <td>201.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.407407</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.925926</td>\n",
       "      <td>3.703704</td>\n",
       "      <td>5.888889</td>\n",
       "      <td>19.629629</td>\n",
       "      <td>6.518518</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-59.909874</td>\n",
       "      <td>-10.010125</td>\n",
       "      <td>218.33334</td>\n",
       "      <td>435.83334</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>523.5</td>\n",
       "      <td>...</td>\n",
       "      <td>5.222222</td>\n",
       "      <td>7.592592</td>\n",
       "      <td>5.370370</td>\n",
       "      <td>4.481482</td>\n",
       "      <td>8.888889</td>\n",
       "      <td>18.888889</td>\n",
       "      <td>5.222222</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 428 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  row  col        lon        lat       bean     carrot  cassava  \\\n",
       "0   0    0    0 -59.989876 -10.010125  200.00000  335.00000    201.0   \n",
       "1   1    0    1 -59.969875 -10.010125  200.00000  335.00000    201.0   \n",
       "2   2    0    2 -59.949875 -10.010125  200.00000  335.00000    201.0   \n",
       "3   3    0    3 -59.929874 -10.010125  200.00000  335.00000    201.0   \n",
       "4   4    0    4 -59.909874 -10.010125  218.33334  435.83334    216.0   \n",
       "\n",
       "   chickpea  citrus  ...  tot_defor_2012_lag_3rd_order  \\\n",
       "0       0.0   391.0  ...                      6.866667   \n",
       "1       0.0   391.0  ...                      5.105263   \n",
       "2       0.0   391.0  ...                      5.913043   \n",
       "3       0.0   391.0  ...                      5.407407   \n",
       "4       0.0   523.5  ...                      5.222222   \n",
       "\n",
       "   tot_defor_2013_lag_3rd_order  tot_defor_2014_lag_3rd_order  \\\n",
       "0                      0.733333                      2.200000   \n",
       "1                      0.526316                      0.947368   \n",
       "2                      4.086957                      4.521739   \n",
       "3                      4.000000                      3.925926   \n",
       "4                      7.592592                      5.370370   \n",
       "\n",
       "   tot_defor_2015_lag_3rd_order  tot_defor_2016_lag_3rd_order  \\\n",
       "0                      4.466667                      9.866667   \n",
       "1                      1.473684                      9.473684   \n",
       "2                      4.956522                      8.695652   \n",
       "3                      3.703704                      5.888889   \n",
       "4                      4.481482                      8.888889   \n",
       "\n",
       "   tot_defor_2017_lag_3rd_order  tot_defor_2018_lag_3rd_order  s  \\\n",
       "0                      6.600000                      0.800000  1   \n",
       "1                      6.210527                      2.000000  1   \n",
       "2                     11.217392                      5.173913  1   \n",
       "3                     19.629629                      6.518518  1   \n",
       "4                     18.888889                      5.222222  1   \n",
       "\n",
       "   D_defor_2018  constant  \n",
       "0         False         1  \n",
       "1          True         1  \n",
       "2         False         1  \n",
       "3         False         1  \n",
       "4          True         1  \n",
       "\n",
       "[5 rows x 428 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View first 5 rows of the data\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "4WU_yntf8Yl7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wdpa_2017</th>\n",
       "      <th>population_2015</th>\n",
       "      <th>chirps_2017</th>\n",
       "      <th>defor_2017</th>\n",
       "      <th>maize</th>\n",
       "      <th>soy</th>\n",
       "      <th>sugarcane</th>\n",
       "      <th>perc_treecover</th>\n",
       "      <th>perm_water</th>\n",
       "      <th>travel_min</th>\n",
       "      <th>...</th>\n",
       "      <th>maize_lag_1st_order</th>\n",
       "      <th>soy_lag_1st_order</th>\n",
       "      <th>sugarcane_lag_1st_order</th>\n",
       "      <th>perc_treecover_lag_1st_order</th>\n",
       "      <th>perm_water_lag_1st_order</th>\n",
       "      <th>travel_min_lag_1st_order</th>\n",
       "      <th>cropland_lag_1st_order</th>\n",
       "      <th>mean_elev_lag_1st_order</th>\n",
       "      <th>sd_elev_lag_1st_order</th>\n",
       "      <th>near_road_lag_1st_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.069316</td>\n",
       "      <td>2038.0789</td>\n",
       "      <td>0.009531</td>\n",
       "      <td>461.00000</td>\n",
       "      <td>209.00000</td>\n",
       "      <td>1295.0000</td>\n",
       "      <td>99.761093</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2612.6440</td>\n",
       "      <td>...</td>\n",
       "      <td>461.00000</td>\n",
       "      <td>209.00000</td>\n",
       "      <td>1295.0000</td>\n",
       "      <td>99.650558</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2590.3511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>238.30879</td>\n",
       "      <td>32.883953</td>\n",
       "      <td>209.46098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.069481</td>\n",
       "      <td>2038.0789</td>\n",
       "      <td>0.006562</td>\n",
       "      <td>461.00000</td>\n",
       "      <td>209.00000</td>\n",
       "      <td>1295.0000</td>\n",
       "      <td>99.777657</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2680.3191</td>\n",
       "      <td>...</td>\n",
       "      <td>473.98245</td>\n",
       "      <td>214.08772</td>\n",
       "      <td>1296.2280</td>\n",
       "      <td>99.635925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2634.8425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>238.81532</td>\n",
       "      <td>32.887760</td>\n",
       "      <td>210.06200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.069645</td>\n",
       "      <td>2037.1292</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>461.00000</td>\n",
       "      <td>209.00000</td>\n",
       "      <td>1295.0000</td>\n",
       "      <td>99.766403</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2796.3284</td>\n",
       "      <td>...</td>\n",
       "      <td>484.59418</td>\n",
       "      <td>218.24637</td>\n",
       "      <td>1297.2319</td>\n",
       "      <td>99.644539</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2677.8906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>238.43069</td>\n",
       "      <td>31.007774</td>\n",
       "      <td>210.43365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.069809</td>\n",
       "      <td>2036.1794</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>461.00000</td>\n",
       "      <td>209.00000</td>\n",
       "      <td>1295.0000</td>\n",
       "      <td>99.814842</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2920.0164</td>\n",
       "      <td>...</td>\n",
       "      <td>492.06171</td>\n",
       "      <td>221.17284</td>\n",
       "      <td>1297.9382</td>\n",
       "      <td>99.604378</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2719.8706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>239.46907</td>\n",
       "      <td>32.033943</td>\n",
       "      <td>210.62392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.075217</td>\n",
       "      <td>2036.1794</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>522.66663</td>\n",
       "      <td>233.16666</td>\n",
       "      <td>1300.8334</td>\n",
       "      <td>99.655937</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2977.4216</td>\n",
       "      <td>...</td>\n",
       "      <td>500.74072</td>\n",
       "      <td>224.57407</td>\n",
       "      <td>1298.7593</td>\n",
       "      <td>99.568802</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2779.6533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>246.70377</td>\n",
       "      <td>34.055607</td>\n",
       "      <td>211.30115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   wdpa_2017  population_2015  chirps_2017  defor_2017      maize        soy  \\\n",
       "0        1.0         0.069316    2038.0789    0.009531  461.00000  209.00000   \n",
       "1        1.0         0.069481    2038.0789    0.006562  461.00000  209.00000   \n",
       "2        1.0         0.069645    2037.1292    0.005313  461.00000  209.00000   \n",
       "3        1.0         0.069809    2036.1794    0.000469  461.00000  209.00000   \n",
       "4        1.0         0.075217    2036.1794    0.000000  522.66663  233.16666   \n",
       "\n",
       "   sugarcane  perc_treecover  perm_water  travel_min  ...  \\\n",
       "0  1295.0000       99.761093         1.0   2612.6440  ...   \n",
       "1  1295.0000       99.777657         1.0   2680.3191  ...   \n",
       "2  1295.0000       99.766403         1.0   2796.3284  ...   \n",
       "3  1295.0000       99.814842         1.0   2920.0164  ...   \n",
       "4  1300.8334       99.655937         1.0   2977.4216  ...   \n",
       "\n",
       "   maize_lag_1st_order  soy_lag_1st_order  sugarcane_lag_1st_order  \\\n",
       "0            461.00000          209.00000                1295.0000   \n",
       "1            473.98245          214.08772                1296.2280   \n",
       "2            484.59418          218.24637                1297.2319   \n",
       "3            492.06171          221.17284                1297.9382   \n",
       "4            500.74072          224.57407                1298.7593   \n",
       "\n",
       "   perc_treecover_lag_1st_order  perm_water_lag_1st_order  \\\n",
       "0                     99.650558                       1.0   \n",
       "1                     99.635925                       1.0   \n",
       "2                     99.644539                       1.0   \n",
       "3                     99.604378                       1.0   \n",
       "4                     99.568802                       1.0   \n",
       "\n",
       "   travel_min_lag_1st_order  cropland_lag_1st_order  mean_elev_lag_1st_order  \\\n",
       "0                 2590.3511                     0.0                238.30879   \n",
       "1                 2634.8425                     0.0                238.81532   \n",
       "2                 2677.8906                     0.0                238.43069   \n",
       "3                 2719.8706                     0.0                239.46907   \n",
       "4                 2779.6533                     0.0                246.70377   \n",
       "\n",
       "   sd_elev_lag_1st_order  near_road_lag_1st_order  \n",
       "0              32.883953                209.46098  \n",
       "1              32.887760                210.06200  \n",
       "2              31.007774                210.43365  \n",
       "3              32.033943                210.62392  \n",
       "4              34.055607                211.30115  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the dependent variable\n",
    "Y = df['D_defor_2018'] # create a vector of just the outcomes  \n",
    "\n",
    "# Define a list of variable names for explanatory variables\n",
    "lstCols = [\n",
    "  'wdpa_2017',\n",
    "  'population_2015',\n",
    "  'chirps_2017',\n",
    "  'defor_2017',\n",
    "  'maize',\n",
    "  'soy',\n",
    "  'sugarcane',\n",
    "  'perc_treecover',\n",
    "  'perm_water',\n",
    "  'travel_min',\n",
    "  'cropland',\n",
    "  # 'pasture',\n",
    "  'mean_elev',\n",
    "  'sd_elev',\n",
    "  'near_road',\n",
    "  'defor_2017_lag_1st_order',\n",
    "  'wdpa_2017_lag_1st_order',\n",
    "  'chirps_2017_lag_1st_order',\n",
    "  'population_2015_lag_1st_order',\n",
    "  'maize_lag_1st_order',\n",
    "  'soy_lag_1st_order',\n",
    "  'sugarcane_lag_1st_order',\n",
    "  'perc_treecover_lag_1st_order',\n",
    "  'perm_water_lag_1st_order',\n",
    "  'travel_min_lag_1st_order',\n",
    "  'cropland_lag_1st_order',\n",
    "  # 'pasture_lag_1st_order',\n",
    "  'mean_elev_lag_1st_order',\n",
    "  'sd_elev_lag_1st_order',\n",
    "  'near_road_lag_1st_order',\n",
    "#  'bean',\n",
    "#  'carrot',\n",
    "#  'cassava',\n",
    "#  'chickpea',\n",
    "#  'citrus',\n",
    "#  'coffee',\n",
    "#  'groundnut',\n",
    "#  'maize',\n",
    "#  'soy',\n",
    "#  'sugarcane',\n",
    "#  'tomato',\n",
    "#  'wheat',\n",
    "#  'defor_2001',\n",
    "#  'defor_2002',\n",
    "#  'defor_2003',\n",
    "#  'defor_2004',\n",
    "#  'defor_2005',\n",
    "#  'defor_2006',\n",
    "#  'defor_2007',\n",
    "#  'defor_2008',\n",
    "#  'defor_2009',\n",
    "#  'defor_2010',\n",
    "#  'defor_2011',\n",
    "#  'defor_2012',\n",
    "#  'defor_2013',\n",
    "#  'defor_2014',\n",
    "#  'defor_2015',\n",
    "#  'defor_2016',\n",
    "#  'defor_2017',\n",
    "#  'near_dist_km',\n",
    "#  'mean_elev_mts',\n",
    "#  'sd_elev_mts',\n",
    " ]\n",
    "\n",
    "# Get the explanatory Variables\n",
    "\n",
    "# .loc is a way to select the columns \n",
    "# `:` selects all the rows\n",
    "# the lstCols is the list of columns we want to select from the data \n",
    "\n",
    "X =  df.loc[:,lstCols]\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "cgPj9lkr8Yl_"
   },
   "outputs": [],
   "source": [
    "# Split the data into train and test data using sklearn train_test_split object\n",
    "\n",
    "#   (see: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    "\n",
    "#   Note: This randomly splits the data in 80% train and 20% test data\n",
    "X_train_raw, X_test_raw, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "SVlC9obC8ggx"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wdpa_2017</th>\n",
       "      <th>population_2015</th>\n",
       "      <th>chirps_2017</th>\n",
       "      <th>defor_2017</th>\n",
       "      <th>maize</th>\n",
       "      <th>soy</th>\n",
       "      <th>sugarcane</th>\n",
       "      <th>perc_treecover</th>\n",
       "      <th>perm_water</th>\n",
       "      <th>travel_min</th>\n",
       "      <th>...</th>\n",
       "      <th>maize_lag_1st_order</th>\n",
       "      <th>soy_lag_1st_order</th>\n",
       "      <th>sugarcane_lag_1st_order</th>\n",
       "      <th>perc_treecover_lag_1st_order</th>\n",
       "      <th>perm_water_lag_1st_order</th>\n",
       "      <th>travel_min_lag_1st_order</th>\n",
       "      <th>cropland_lag_1st_order</th>\n",
       "      <th>mean_elev_lag_1st_order</th>\n",
       "      <th>sd_elev_lag_1st_order</th>\n",
       "      <th>near_road_lag_1st_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84215</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.312662</td>\n",
       "      <td>1994.8783</td>\n",
       "      <td>0.004531</td>\n",
       "      <td>1399.0000</td>\n",
       "      <td>876.0000</td>\n",
       "      <td>3225.0000</td>\n",
       "      <td>13.787031</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>311.74936</td>\n",
       "      <td>...</td>\n",
       "      <td>1412.42990</td>\n",
       "      <td>865.31073</td>\n",
       "      <td>3245.2070</td>\n",
       "      <td>39.435654</td>\n",
       "      <td>1.000055</td>\n",
       "      <td>323.294010</td>\n",
       "      <td>0.111629</td>\n",
       "      <td>425.817570</td>\n",
       "      <td>8.508912</td>\n",
       "      <td>6.529878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238089</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065439</td>\n",
       "      <td>1084.3052</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3680.6667</td>\n",
       "      <td>1250.3334</td>\n",
       "      <td>2695.1665</td>\n",
       "      <td>3.203906</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>175.28607</td>\n",
       "      <td>...</td>\n",
       "      <td>3570.30620</td>\n",
       "      <td>1215.71640</td>\n",
       "      <td>2621.8599</td>\n",
       "      <td>4.183395</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>169.653210</td>\n",
       "      <td>0.042010</td>\n",
       "      <td>83.092270</td>\n",
       "      <td>2.305456</td>\n",
       "      <td>3.514460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134121</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.836103</td>\n",
       "      <td>1612.0486</td>\n",
       "      <td>0.029687</td>\n",
       "      <td>1908.0000</td>\n",
       "      <td>928.0000</td>\n",
       "      <td>2559.0000</td>\n",
       "      <td>21.228437</td>\n",
       "      <td>1.000156</td>\n",
       "      <td>1022.87950</td>\n",
       "      <td>...</td>\n",
       "      <td>1907.59310</td>\n",
       "      <td>917.14758</td>\n",
       "      <td>2548.5867</td>\n",
       "      <td>59.743820</td>\n",
       "      <td>1.000423</td>\n",
       "      <td>968.982120</td>\n",
       "      <td>0.050072</td>\n",
       "      <td>187.344120</td>\n",
       "      <td>8.212090</td>\n",
       "      <td>27.280664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228121</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166125</td>\n",
       "      <td>1127.9695</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3171.0000</td>\n",
       "      <td>1105.0000</td>\n",
       "      <td>3007.0000</td>\n",
       "      <td>0.020312</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.71125</td>\n",
       "      <td>...</td>\n",
       "      <td>3205.64060</td>\n",
       "      <td>1113.96120</td>\n",
       "      <td>3015.7854</td>\n",
       "      <td>21.625488</td>\n",
       "      <td>1.033119</td>\n",
       "      <td>92.096024</td>\n",
       "      <td>0.002361</td>\n",
       "      <td>86.587601</td>\n",
       "      <td>1.625926</td>\n",
       "      <td>2.449462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22138</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015828</td>\n",
       "      <td>1991.5323</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>374.0000</td>\n",
       "      <td>192.0000</td>\n",
       "      <td>838.0000</td>\n",
       "      <td>80.983437</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>744.65094</td>\n",
       "      <td>...</td>\n",
       "      <td>573.85535</td>\n",
       "      <td>308.49075</td>\n",
       "      <td>1364.2876</td>\n",
       "      <td>89.668381</td>\n",
       "      <td>1.005173</td>\n",
       "      <td>839.513000</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>348.337860</td>\n",
       "      <td>27.602272</td>\n",
       "      <td>251.398510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        wdpa_2017  population_2015  chirps_2017  defor_2017      maize  \\\n",
       "84215         0.0         0.312662    1994.8783    0.004531  1399.0000   \n",
       "238089        0.0         0.065439    1084.3052    0.000000  3680.6667   \n",
       "134121        0.0         0.836103    1612.0486    0.029687  1908.0000   \n",
       "228121        0.0         0.166125    1127.9695    0.000000  3171.0000   \n",
       "22138         0.0         0.015828    1991.5323    0.000156   374.0000   \n",
       "\n",
       "              soy  sugarcane  perc_treecover  perm_water  travel_min  ...  \\\n",
       "84215    876.0000  3225.0000       13.787031    1.000000   311.74936  ...   \n",
       "238089  1250.3334  2695.1665        3.203906    1.000000   175.28607  ...   \n",
       "134121   928.0000  2559.0000       21.228437    1.000156  1022.87950  ...   \n",
       "228121  1105.0000  3007.0000        0.020312    1.000000    60.71125  ...   \n",
       "22138    192.0000   838.0000       80.983437    1.000000   744.65094  ...   \n",
       "\n",
       "        maize_lag_1st_order  soy_lag_1st_order  sugarcane_lag_1st_order  \\\n",
       "84215            1412.42990          865.31073                3245.2070   \n",
       "238089           3570.30620         1215.71640                2621.8599   \n",
       "134121           1907.59310          917.14758                2548.5867   \n",
       "228121           3205.64060         1113.96120                3015.7854   \n",
       "22138             573.85535          308.49075                1364.2876   \n",
       "\n",
       "        perc_treecover_lag_1st_order  perm_water_lag_1st_order  \\\n",
       "84215                      39.435654                  1.000055   \n",
       "238089                      4.183395                  1.000000   \n",
       "134121                     59.743820                  1.000423   \n",
       "228121                     21.625488                  1.033119   \n",
       "22138                      89.668381                  1.005173   \n",
       "\n",
       "        travel_min_lag_1st_order  cropland_lag_1st_order  \\\n",
       "84215                 323.294010                0.111629   \n",
       "238089                169.653210                0.042010   \n",
       "134121                968.982120                0.050072   \n",
       "228121                 92.096024                0.002361   \n",
       "22138                 839.513000                0.000054   \n",
       "\n",
       "        mean_elev_lag_1st_order  sd_elev_lag_1st_order  \\\n",
       "84215                425.817570               8.508912   \n",
       "238089                83.092270               2.305456   \n",
       "134121               187.344120               8.212090   \n",
       "228121                86.587601               1.625926   \n",
       "22138                348.337860              27.602272   \n",
       "\n",
       "        near_road_lag_1st_order  \n",
       "84215                  6.529878  \n",
       "238089                 3.514460  \n",
       "134121                27.280664  \n",
       "228121                 2.449462  \n",
       "22138                251.398510  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_raw.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "DFhM3lFp8YmE"
   },
   "outputs": [],
   "source": [
    "# Scale data to 0-1 range using sklearn MinMaxScalar object. This facilitates training the model\n",
    "# (see: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)\n",
    "scaler = MinMaxScaler()\n",
    "# Use only the train data to fit the MinMaxScalar\n",
    "scaler.fit(X_train_raw)\n",
    "\n",
    "# Apply the MinMax transformation to the train and test data\n",
    "X_train = scaler.transform(X_train_raw)\n",
    "X_test = scaler.transform(X_test_raw)\n",
    "# Note the depended variable does not need to be scaled as it is a binary variable anyway\n",
    "\n",
    "# don't understand why this transformation is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "MCc0Axm79fvz"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.624824</td>\n",
       "      <td>0.004531</td>\n",
       "      <td>0.212786</td>\n",
       "      <td>0.426647</td>\n",
       "      <td>0.511770</td>\n",
       "      <td>0.137870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199981</td>\n",
       "      <td>0.398449</td>\n",
       "      <td>0.494724</td>\n",
       "      <td>0.394371</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.087877</td>\n",
       "      <td>0.115798</td>\n",
       "      <td>0.379887</td>\n",
       "      <td>0.085298</td>\n",
       "      <td>0.015680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.131519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.578380</td>\n",
       "      <td>0.613440</td>\n",
       "      <td>0.426341</td>\n",
       "      <td>0.032039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045866</td>\n",
       "      <td>...</td>\n",
       "      <td>0.565090</td>\n",
       "      <td>0.584035</td>\n",
       "      <td>0.388770</td>\n",
       "      <td>0.041815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045230</td>\n",
       "      <td>0.043579</td>\n",
       "      <td>0.003596</td>\n",
       "      <td>0.019457</td>\n",
       "      <td>0.007139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.417425</td>\n",
       "      <td>0.029687</td>\n",
       "      <td>0.294344</td>\n",
       "      <td>0.452595</td>\n",
       "      <td>0.404386</td>\n",
       "      <td>0.212284</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.268932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.283762</td>\n",
       "      <td>0.425903</td>\n",
       "      <td>0.376315</td>\n",
       "      <td>0.597472</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>0.267105</td>\n",
       "      <td>0.051942</td>\n",
       "      <td>0.118058</td>\n",
       "      <td>0.082148</td>\n",
       "      <td>0.074452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.155174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.496715</td>\n",
       "      <td>0.540918</td>\n",
       "      <td>0.476620</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.503389</td>\n",
       "      <td>0.530142</td>\n",
       "      <td>0.455728</td>\n",
       "      <td>0.216252</td>\n",
       "      <td>0.040832</td>\n",
       "      <td>0.023701</td>\n",
       "      <td>0.002449</td>\n",
       "      <td>0.007434</td>\n",
       "      <td>0.012245</td>\n",
       "      <td>0.004123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.623011</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.048550</td>\n",
       "      <td>0.085329</td>\n",
       "      <td>0.126895</td>\n",
       "      <td>0.809834</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.195709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058095</td>\n",
       "      <td>0.103538</td>\n",
       "      <td>0.175014</td>\n",
       "      <td>0.896746</td>\n",
       "      <td>0.006377</td>\n",
       "      <td>0.231168</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.294819</td>\n",
       "      <td>0.287948</td>\n",
       "      <td>0.709223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0         1         2         3         4         5         6         7   \\\n",
       "0  0.0  0.000047  0.624824  0.004531  0.212786  0.426647  0.511770  0.137870   \n",
       "1  0.0  0.000010  0.131519  0.000000  0.578380  0.613440  0.426341  0.032039   \n",
       "2  0.0  0.000127  0.417425  0.029687  0.294344  0.452595  0.404386  0.212284   \n",
       "3  0.0  0.000025  0.155174  0.000000  0.496715  0.540918  0.476620  0.000203   \n",
       "4  0.0  0.000002  0.623011  0.000156  0.048550  0.085329  0.126895  0.809834   \n",
       "\n",
       "         8         9   ...        18        19        20        21        22  \\\n",
       "0  0.000000  0.081780  ...  0.199981  0.398449  0.494724  0.394371  0.000068   \n",
       "1  0.000000  0.045866  ...  0.565090  0.584035  0.388770  0.041815  0.000000   \n",
       "2  0.000156  0.268932  ...  0.283762  0.425903  0.376315  0.597472  0.000522   \n",
       "3  0.000000  0.015713  ...  0.503389  0.530142  0.455728  0.216252  0.040832   \n",
       "4  0.000000  0.195709  ...  0.058095  0.103538  0.175014  0.896746  0.006377   \n",
       "\n",
       "         23        24        25        26        27  \n",
       "0  0.087877  0.115798  0.379887  0.085298  0.015680  \n",
       "1  0.045230  0.043579  0.003596  0.019457  0.007139  \n",
       "2  0.267105  0.051942  0.118058  0.082148  0.074452  \n",
       "3  0.023701  0.002449  0.007434  0.012245  0.004123  \n",
       "4  0.231168  0.000056  0.294819  0.287948  0.709223  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf = pd.DataFrame(X_train)\n",
    "traindf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "F45G02gc8YmH"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, penalty=None, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000, penalty=None, random_state=0)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, penalty=None, random_state=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a logistic regression model using sklearn (see: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "# Create the model object\n",
    "modelLg = LogisticRegression(random_state=0,penalty=None,fit_intercept=True, max_iter=1000)\n",
    "# Fit the model using the training data\n",
    "modelLg.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e-yYdgmJ8YmM"
   },
   "source": [
    "### Note:\n",
    "sklearn is a popular ML libary that we will primarily use in the course. While sklearn allows to run\n",
    "regressions it does not provide regression table outputs (with p-values, standard errors etc.).\n",
    "While those table are very common in econometrics they are not commonly considered in the ML\n",
    "community. For illustrative puposes we do the calculation for a regression table manually, however,\n",
    "there is also a \"statsmodels\" libary in python that does this automatically (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "bWVvG9Nb8YmN"
   },
   "outputs": [],
   "source": [
    "# Function to calculate pvalues and standard errors for a scikit-learn logisticRegression\n",
    "# Source: https://stackoverflow.com/questions/25122999/scikit-learn-how-to-check-coefficients-significance\n",
    "def logit_pvalue(model, x):\n",
    "    \"\"\" Calculate z-scores for scikit-learn LogisticRegression.\n",
    "    parameters:\n",
    "        model: fitted sklearn.linear_model.LogisticRegression with intercept and large C\n",
    "        x:     matrix on which the model was fit\n",
    "    This function uses asymtptics for maximum likelihood estimates.\n",
    "    \"\"\"\n",
    "    p = model.predict_proba(x)\n",
    "    n = len(p)\n",
    "    m = len(model.coef_[0]) + 1\n",
    "    # m = len(model.coef_[0])\n",
    "    # coefs = model.coef_[0]\n",
    "    coefs = np.concatenate([model.intercept_, model.coef_[0]])\n",
    "    x_full = np.matrix(np.insert(np.array(x), 0, 1, axis = 1))\n",
    "    ans = np.zeros((m, m))\n",
    "    for i in range(n):\n",
    "        ans = ans + np.dot(np.transpose(x_full[i, :]), x_full[i, :]) * p[i,1] * p[i, 0]\n",
    "    vcov = np.linalg.inv(np.matrix(ans))\n",
    "    se = np.sqrt(np.diag(vcov))\n",
    "    t =  coefs/se\n",
    "    p = (1 - norm.cdf(abs(t))) * 2\n",
    "    return se, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "3ORdUGhf8YmR"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>se</th>\n",
       "      <th>pval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>constant</th>\n",
       "      <td>-1.938529</td>\n",
       "      <td>0.034284</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdpa_2017</th>\n",
       "      <td>-0.473744</td>\n",
       "      <td>0.064229</td>\n",
       "      <td>1.632028e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population_2015</th>\n",
       "      <td>0.789097</td>\n",
       "      <td>0.488295</td>\n",
       "      <td>1.060891e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chirps_2017</th>\n",
       "      <td>1.274356</td>\n",
       "      <td>0.690596</td>\n",
       "      <td>6.499398e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>defor_2017</th>\n",
       "      <td>14.286842</td>\n",
       "      <td>0.288499</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maize</th>\n",
       "      <td>0.404382</td>\n",
       "      <td>0.769550</td>\n",
       "      <td>5.992509e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soy</th>\n",
       "      <td>1.452906</td>\n",
       "      <td>0.575346</td>\n",
       "      <td>1.156087e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sugarcane</th>\n",
       "      <td>-1.324143</td>\n",
       "      <td>0.509393</td>\n",
       "      <td>9.337285e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perc_treecover</th>\n",
       "      <td>0.686018</td>\n",
       "      <td>0.032792</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perm_water</th>\n",
       "      <td>-0.378337</td>\n",
       "      <td>0.275854</td>\n",
       "      <td>1.702165e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>travel_min</th>\n",
       "      <td>-1.347930</td>\n",
       "      <td>0.343395</td>\n",
       "      <td>8.662092e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cropland</th>\n",
       "      <td>-0.080388</td>\n",
       "      <td>0.188927</td>\n",
       "      <td>6.704750e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_elev</th>\n",
       "      <td>-4.046016</td>\n",
       "      <td>0.202591</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sd_elev</th>\n",
       "      <td>0.331512</td>\n",
       "      <td>0.135474</td>\n",
       "      <td>1.440307e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>near_road</th>\n",
       "      <td>0.389143</td>\n",
       "      <td>1.786290</td>\n",
       "      <td>8.275463e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>defor_2017_lag_1st_order</th>\n",
       "      <td>3.462009</td>\n",
       "      <td>0.169524</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdpa_2017_lag_1st_order</th>\n",
       "      <td>-0.889972</td>\n",
       "      <td>0.071399</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chirps_2017_lag_1st_order</th>\n",
       "      <td>1.643381</td>\n",
       "      <td>0.679249</td>\n",
       "      <td>1.554572e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population_2015_lag_1st_order</th>\n",
       "      <td>2.405398</td>\n",
       "      <td>0.379340</td>\n",
       "      <td>2.282730e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maize_lag_1st_order</th>\n",
       "      <td>-0.684987</td>\n",
       "      <td>0.750115</td>\n",
       "      <td>3.611497e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soy_lag_1st_order</th>\n",
       "      <td>0.685488</td>\n",
       "      <td>0.556797</td>\n",
       "      <td>2.182754e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sugarcane_lag_1st_order</th>\n",
       "      <td>-2.617726</td>\n",
       "      <td>0.501391</td>\n",
       "      <td>1.780313e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perc_treecover_lag_1st_order</th>\n",
       "      <td>0.097829</td>\n",
       "      <td>0.047171</td>\n",
       "      <td>3.808668e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perm_water_lag_1st_order</th>\n",
       "      <td>-3.332169</td>\n",
       "      <td>0.400607</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>travel_min_lag_1st_order</th>\n",
       "      <td>-1.470013</td>\n",
       "      <td>0.352500</td>\n",
       "      <td>3.042721e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cropland_lag_1st_order</th>\n",
       "      <td>0.651440</td>\n",
       "      <td>0.203391</td>\n",
       "      <td>1.360559e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_elev_lag_1st_order</th>\n",
       "      <td>2.548996</td>\n",
       "      <td>0.205695</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sd_elev_lag_1st_order</th>\n",
       "      <td>2.001654</td>\n",
       "      <td>0.099013</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>near_road_lag_1st_order</th>\n",
       "      <td>0.613128</td>\n",
       "      <td>1.764830</td>\n",
       "      <td>7.282797e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    coef        se          pval\n",
       "constant                       -1.938529  0.034284  0.000000e+00\n",
       "wdpa_2017                      -0.473744  0.064229  1.632028e-13\n",
       "population_2015                 0.789097  0.488295  1.060891e-01\n",
       "chirps_2017                     1.274356  0.690596  6.499398e-02\n",
       "defor_2017                     14.286842  0.288499  0.000000e+00\n",
       "maize                           0.404382  0.769550  5.992509e-01\n",
       "soy                             1.452906  0.575346  1.156087e-02\n",
       "sugarcane                      -1.324143  0.509393  9.337285e-03\n",
       "perc_treecover                  0.686018  0.032792  0.000000e+00\n",
       "perm_water                     -0.378337  0.275854  1.702165e-01\n",
       "travel_min                     -1.347930  0.343395  8.662092e-05\n",
       "cropland                       -0.080388  0.188927  6.704750e-01\n",
       "mean_elev                      -4.046016  0.202591  0.000000e+00\n",
       "sd_elev                         0.331512  0.135474  1.440307e-02\n",
       "near_road                       0.389143  1.786290  8.275463e-01\n",
       "defor_2017_lag_1st_order        3.462009  0.169524  0.000000e+00\n",
       "wdpa_2017_lag_1st_order        -0.889972  0.071399  0.000000e+00\n",
       "chirps_2017_lag_1st_order       1.643381  0.679249  1.554572e-02\n",
       "population_2015_lag_1st_order   2.405398  0.379340  2.282730e-10\n",
       "maize_lag_1st_order            -0.684987  0.750115  3.611497e-01\n",
       "soy_lag_1st_order               0.685488  0.556797  2.182754e-01\n",
       "sugarcane_lag_1st_order        -2.617726  0.501391  1.780313e-07\n",
       "perc_treecover_lag_1st_order    0.097829  0.047171  3.808668e-02\n",
       "perm_water_lag_1st_order       -3.332169  0.400607  0.000000e+00\n",
       "travel_min_lag_1st_order       -1.470013  0.352500  3.042721e-05\n",
       "cropland_lag_1st_order          0.651440  0.203391  1.360559e-03\n",
       "mean_elev_lag_1st_order         2.548996  0.205695  0.000000e+00\n",
       "sd_elev_lag_1st_order           2.001654  0.099013  0.000000e+00\n",
       "near_road_lag_1st_order         0.613128  1.764830  7.282797e-01"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the previously created function to create a regression output table\n",
    "se, p = logit_pvalue(modelLg, X_train)\n",
    "coefs = np.concatenate([modelLg.intercept_, modelLg.coef_[0]]).T\n",
    "resCoef = pd.DataFrame(coefs,index=['constant']+lstCols)\n",
    "resCoef.columns = ['coef']\n",
    "resCoef['se'] = se\n",
    "resCoef['pval'] = p\n",
    "resCoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "bRYFl12K8YmV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.469925\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:           D_defor_2018   No. Observations:               199952\n",
      "Model:                          Logit   Df Residuals:                   199923\n",
      "Method:                           MLE   Df Model:                           28\n",
      "Date:                Mon, 30 Sep 2024   Pseudo R-squ.:                  0.1457\n",
      "Time:                        13:49:48   Log-Likelihood:                -93963.\n",
      "converged:                       True   LL-Null:                   -1.0999e+05\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "=================================================================================================\n",
      "                                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------\n",
      "const                            -1.9166      0.034    -55.839      0.000      -1.984      -1.849\n",
      "wdpa_2017                        -0.4501      0.064     -7.009      0.000      -0.576      -0.324\n",
      "population_2015                  -0.0805      0.507     -0.159      0.874      -1.074       0.913\n",
      "chirps_2017                      -0.0058      0.691     -0.008      0.993      -1.359       1.348\n",
      "defor_2017                       13.8600      0.285     48.677      0.000      13.302      14.418\n",
      "maize                             1.9689      0.769      2.559      0.010       0.461       3.477\n",
      "soy                              -0.5210      0.575     -0.906      0.365      -1.649       0.607\n",
      "sugarcane                        -0.3133      0.509     -0.615      0.539      -1.312       0.685\n",
      "perc_treecover                    0.6601      0.033     20.133      0.000       0.596       0.724\n",
      "perm_water                        0.7695      0.261      2.944      0.003       0.257       1.282\n",
      "travel_min                       -0.7681      0.344     -2.236      0.025      -1.441      -0.095\n",
      "cropland                         -0.0226      0.189     -0.120      0.905      -0.393       0.347\n",
      "mean_elev                        -4.2050      0.203    -20.698      0.000      -4.603      -3.807\n",
      "sd_elev                           0.5271      0.135      3.894      0.000       0.262       0.792\n",
      "near_road                        -5.4434      1.791     -3.040      0.002      -8.953      -1.934\n",
      "defor_2017_lag_1st_order          3.7240      0.170     21.937      0.000       3.391       4.057\n",
      "wdpa_2017_lag_1st_order          -0.9101      0.071    -12.744      0.000      -1.050      -0.770\n",
      "chirps_2017_lag_1st_order         2.9280      0.679      4.311      0.000       1.597       4.259\n",
      "population_2015_lag_1st_order     3.1625      0.389      8.132      0.000       2.400       3.925\n",
      "maize_lag_1st_order              -2.0904      0.750     -2.787      0.005      -3.561      -0.620\n",
      "soy_lag_1st_order                 2.5635      0.557      4.605      0.000       1.472       3.655\n",
      "sugarcane_lag_1st_order          -3.6844      0.502     -7.345      0.000      -4.668      -2.701\n",
      "perc_treecover_lag_1st_order      0.1187      0.047      2.518      0.012       0.026       0.211\n",
      "perm_water_lag_1st_order         -5.1062      0.444    -11.511      0.000      -5.976      -4.237\n",
      "travel_min_lag_1st_order         -2.0269      0.353     -5.747      0.000      -2.718      -1.336\n",
      "cropland_lag_1st_order            0.5832      0.203      2.867      0.004       0.185       0.982\n",
      "mean_elev_lag_1st_order           2.7371      0.206     13.272      0.000       2.333       3.141\n",
      "sd_elev_lag_1st_order             1.8477      0.099     18.623      0.000       1.653       2.042\n",
      "near_road_lag_1st_order           6.3655      1.769      3.598      0.000       2.898       9.833\n",
      "=================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Confirm the results using statsmodels\n",
    "import statsmodels.api as sm\n",
    "# Add constant to X matrix\n",
    "X_train_const = np.matrix(np.insert(np.array(X_train), 0, 1, axis = 1))\n",
    "\n",
    "# Define the logit regression\n",
    "logit = sm.Logit(Y_train,X_train_const)\n",
    "\n",
    "# Set the names of the explanatory variables\n",
    "logit.data.xnames = exog_names=['const']+lstCols\n",
    "\n",
    "# fit the model\n",
    "result = logit.fit()\n",
    "# Print the summary table\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hwbd1OKA8Ymg"
   },
   "source": [
    "## Train your first very (very) simple neural network using sklearn\n",
    "Now use a neural network for the same problem. In the course you will see that this is actually equivalent to a logistic regression, hence a logistic regression is in fact a specific form of a neural network!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_6bKms58Ymg"
   },
   "source": [
    "### Perform a hyper parameter search to tune the learning rate for training the NN.\n",
    "This step is optional and takes a while. You can also run the next cell,\n",
    "using a fixed learning rate. The learning rate was determined using this hyper parameter search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ArwpfQ5I8Ymi"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import loguniform\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'alpha':loguniform(1e-6, 1e-1)}\n",
    "\n",
    "modelNN = MLPClassifier(solver='lbfgs', activation = 'identity',\n",
    "                     hidden_layer_sizes=(1), random_state=1, verbose=True,max_iter=200)\n",
    "\n",
    "\n",
    "clf = RandomizedSearchCV(modelNN, param_grid, random_state=0,n_iter=10,cv=5)\n",
    "\n",
    "X_train_const_ = np.asarray(X_train_const)\n",
    "Y_train_ = np.asarray(Y_train)\n",
    "modelNN = clf.fit(X_train_const_, Y_train_)\n",
    "modelNN.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fuVenVfW8Ymk"
   },
   "source": [
    "### Train the Neural Network with a fixed set of hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aPdSWMNX8Yml"
   },
   "outputs": [],
   "source": [
    "modelNN = MLPClassifier(solver='lbfgs', alpha=8.264328927007723e-05,activation = 'identity',\n",
    "                     hidden_layer_sizes=(1), random_state=1, verbose=True,max_iter=200)\n",
    "\n",
    "modelNN.fit(X_train_const_, Y_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3N3xe5ve8Ymo"
   },
   "outputs": [],
   "source": [
    "# Add the estimated coefficient of the NN to the regression table we created above-\n",
    "# In the course we will discuss why the estimated coefficient are similar.\n",
    "#    modelNN.coefs_[0] are the coefficients of the first layer\n",
    "#    modelNN.coefs_[1][0][0] is the coefficients of the hidden layer\n",
    "resCoef['coef_NN'] = modelNN.coefs_[0]*modelNN.coefs_[1][0][0]\n",
    "resCoef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KGP8hkW28Yms"
   },
   "source": [
    "### Compare the model outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IT1FnBrn8Ymu"
   },
   "outputs": [],
   "source": [
    "# Add constant to the test data\n",
    "X_test_const = np.asarray(np.insert(np.array(X_test), 0, 1, axis = 1))\n",
    "# Get predicted values from logit model\n",
    "Y_test_Lg = modelLg.predict(X_test)\n",
    "# Get predicted values from NN model\n",
    "Y_test_NN = modelNN.predict(X_test_const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Um1zNIHj8Ymx"
   },
   "outputs": [],
   "source": [
    "score_Lg = np.sum(Y_test==Y_test_Lg)/Y_test.shape[0]\n",
    "score_NN = np.sum(Y_test==Y_test_NN)/Y_test.shape[0]\n",
    "print('Score lg (R²): ',score_Lg)\n",
    "print('Score NN (R²): ',score_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FKKjn2W58Ym2"
   },
   "outputs": [],
   "source": [
    "# plot the predicted probabalities of the logit and NN models\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n",
    "\n",
    "pd.DataFrame(modelLg.predict_proba(X_test))[1].hist(bins=100,ax=ax1)\n",
    "pd.DataFrame(modelNN.predict_proba(X_test_const))[1].hist(bins=100,ax=ax2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DerYBK448Ym5"
   },
   "source": [
    "### Well done!!!\n",
    "Now it is your turn. Play around with the notebook to make your very first steps with numpy/pandas and sklearn. In the intro text in the beginning there are some suggestions of what you can try.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GTeZV4aa8Ym6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "vscode": {
   "interpreter": {
    "hash": "b2dd1c5c1941d22dfbdf86f16c96d8db5c09a3d6da608d7809bd79814f897e15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
